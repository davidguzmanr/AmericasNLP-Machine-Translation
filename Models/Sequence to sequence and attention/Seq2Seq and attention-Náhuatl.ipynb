{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confirmed-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parliamentary-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart CUDA\n",
    "# sudo rmmod nvidia_uvm\n",
    "# sudo modprobe nvidia_uvm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-sharp",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "micro-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brief-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    \"\"\"\n",
    "    Removes accents\n",
    "    \"\"\"\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "manufactured-brand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hola me llamo tu mama para saber como estabas'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodeToAscii('hola me llamó tu mamá para saber cómo estabas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incoming-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_langs(file1, file2, final_file):\n",
    "    \"\"\"\n",
    "    Join to files in different langs to reuse the code.\n",
    "    \"\"\"\n",
    "    \n",
    "    lines1 = open(file1).readlines()\n",
    "    lines2 = open(file2).readlines()\n",
    "    \n",
    "    file = open(final_file, 'w')\n",
    "    \n",
    "    for line1, line2 in zip(lines1, lines2):\n",
    "        line1 = line1.replace('\\n', '')\n",
    "        line2 = line2.replace('\\n', '')\n",
    "        line = line1 + '\\t' + line2 + '\\n'\n",
    "\n",
    "        file.write(line)   \n",
    "        \n",
    "    file.close()\n",
    "    print('Finished. # of sentences: {}'.format(len(lines1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "commercial-andrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. # of sentences: 16145\n"
     ]
    }
   ],
   "source": [
    "join_langs('../../data/nahuatl-spanish/train.es', \n",
    "           '../../data/nahuatl-spanish/train.nah',\n",
    "           'data/es-nah.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "welsh-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "diagnostic-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-wheel",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "- Read text file and split into lines, split lines into pairs\n",
    "- Normalize text, filter by length and content\n",
    "- Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "athletic-master",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 16145 sentence pairs\n",
      "Trimmed to 6379 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "Input es 4112\n",
      "Output nah 6176\n",
      "['quiebraplatos', 'kaxtapan']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(f'Input {input_lang.name} {input_lang.n_words}')\n",
    "    print(f'Output {output_lang.name} {output_lang.n_words}')\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('es', 'nah', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-cooper",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "passive-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unnecessary-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "selective-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-walter",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-purchase",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mental-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "descending-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "vanilla-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-shopper",
   "metadata": {},
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "- Start a timer\n",
    "- Initialize optimizers and criterion\n",
    "- Create set of training pairs\n",
    "- Start empty losses array for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "associate-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "smoking-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-estate",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eastern-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "spoken-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-roman",
   "metadata": {},
   "source": [
    "## Training and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "healthy-crash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6176, 4112)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.n_words, input_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "arbitrary-peeing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 33s (- 16m 19s) (2500 3%) 4.6169\n",
      "1m 4s (- 14m 57s) (5000 6%) 4.2307\n",
      "1m 35s (- 14m 15s) (7500 10%) 3.9650\n",
      "2m 6s (- 13m 41s) (10000 13%) 3.8890\n",
      "2m 37s (- 13m 5s) (12500 16%) 3.5804\n",
      "3m 7s (- 12m 30s) (15000 20%) 3.5066\n",
      "3m 39s (- 12m 0s) (17500 23%) 3.2851\n",
      "4m 10s (- 11m 30s) (20000 26%) 3.1363\n",
      "4m 42s (- 10m 59s) (22500 30%) 2.9304\n",
      "5m 12s (- 10m 25s) (25000 33%) 2.7839\n",
      "5m 44s (- 9m 54s) (27500 36%) 2.6397\n",
      "6m 15s (- 9m 22s) (30000 40%) 2.5065\n",
      "6m 46s (- 8m 51s) (32500 43%) 2.3660\n",
      "7m 17s (- 8m 20s) (35000 46%) 2.2599\n",
      "7m 49s (- 7m 49s) (37500 50%) 2.1968\n",
      "8m 21s (- 7m 18s) (40000 53%) 2.0192\n",
      "8m 52s (- 6m 47s) (42500 56%) 1.8678\n",
      "9m 25s (- 6m 16s) (45000 60%) 1.8429\n",
      "9m 58s (- 5m 46s) (47500 63%) 1.6489\n",
      "10m 30s (- 5m 15s) (50000 66%) 1.6024\n",
      "11m 2s (- 4m 44s) (52500 70%) 1.5000\n",
      "11m 35s (- 4m 12s) (55000 73%) 1.3590\n",
      "12m 7s (- 3m 41s) (57500 76%) 1.2662\n",
      "12m 40s (- 3m 10s) (60000 80%) 1.1712\n",
      "13m 11s (- 2m 38s) (62500 83%) 1.1223\n",
      "13m 44s (- 2m 6s) (65000 86%) 1.0546\n",
      "14m 17s (- 1m 35s) (67500 90%) 0.9815\n",
      "14m 50s (- 1m 3s) (70000 93%) 0.9248\n",
      "15m 22s (- 0m 31s) (72500 96%) 0.8914\n",
      "15m 56s (- 0m 0s) (75000 100%) 0.7940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=2500, plot_every=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ideal-combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> asi fue como llegaron aca los tecuanipantlacas .\n",
      "= oca yhuin yn huallaque yn tequanipan tlaca .\n",
      "< oca yhuin yn huallaque yn tequanipan tlaca . <EOS>\n",
      "\n",
      ">  tu atajalo !\n",
      "=  tehhua xictzacuili !\n",
      "<  tehhua xictzacuili ! <EOS>\n",
      "\n",
      "> vender\n",
      "= tlanamaca\n",
      "< ontlazohtlaqueh <EOS>\n",
      "\n",
      "> cada hombre tiene tus preocupaciones .\n",
      "= cocentlacatl quinpiah iyoltspacholtin .\n",
      "< cocentlacatl quinpiah iyoltspacholtin . <EOS>\n",
      "\n",
      "> aqui te voy a dar esta pequena remuneracion .\n",
      "= nican nimitzmacati nehin taxtahuiltzin .\n",
      "< nican nimitzmactiliti nehin . <EOS>\n",
      "\n",
      "> otro poco\n",
      "= octepitzin\n",
      "< tepitzin ne <EOS>\n",
      "\n",
      "> si hay que limpiarla .\n",
      "= kemaj momeujtani .\n",
      "< kemaj momeujtani . <EOS>\n",
      "\n",
      "> azucar o miel al gusto\n",
      "= tlatzopeliloni ahzo necuhtli . ixquich in monequiz\n",
      "< tlatzopeliloni ahzo necuhtli . in ixquich . <EOS>\n",
      "\n",
      "> hacia arriba\n",
      "= ahcopa\n",
      "< ahcopa <EOS>\n",
      "\n",
      "> se reproduce por la semilla .\n",
      "= ixua isemilla .\n",
      "< ixua isemilla . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "scientific-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "#     showAttention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "virtual-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'rico'\n",
    "\n",
    "output_words, attentions = evaluate(encoder1, attn_decoder1, input_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-skating",
   "metadata": {},
   "source": [
    "Tratemos con algunas oraciones del conjunto de development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "behavioral-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ella siguio hablando\n",
      "Gold: ya quicencuilihqui tlahtoa\n",
      "Output: yehua ce yehua . <EOS>\n"
     ]
    }
   ],
   "source": [
    "input_sentence = 'ella siguio hablando'\n",
    "gold_reference = 'ya quicencuilihqui tlahtoa'\n",
    "output_words, _ = evaluate(encoder1, attn_decoder1, input_sentence)\n",
    "\n",
    "print(f'Input: {input_sentence}')\n",
    "print(f'Gold: {gold_reference}')\n",
    "print(f'Output: {\" \".join(output_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "patent-garbage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: no tengo mucho dinero en este momento\n",
      "Gold: Naman axnicpiya tomintzin.\n",
      "Output: amo ce amo ce ce <EOS>\n"
     ]
    }
   ],
   "source": [
    "input_sentence = 'no tengo mucho dinero en este momento'\n",
    "gold_reference = 'Naman axnicpiya tomintzin.'\n",
    "output_words, _ = evaluate(encoder1, attn_decoder1, input_sentence)\n",
    "\n",
    "print(f'Input: {input_sentence}')\n",
    "print(f'Gold: {gold_reference}')\n",
    "print(f'Output: {\" \".join(output_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "japanese-halifax",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = ella siguio hablando\n",
      "output = yehua ce yehua . <EOS>\n",
      "input = la hermana de la abuela no era blanca\n",
      "output = itla ne ueyi ueyi  <EOS>\n"
     ]
    }
   ],
   "source": [
    "# ya quicencuilihqui tlahtoa.\n",
    "evaluateAndShowAttention('ella siguio hablando')\n",
    "\n",
    "# ihueltiuh in cihtli ixchipahuac catca\n",
    "evaluateAndShowAttention('la hermana de la abuela no era blanca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "conscious-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "saved-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_report(sys, ref, score_only):\n",
    "\n",
    "    chrf = sacrebleu.corpus_chrf(sys, ref)\n",
    "    bleu = sacrebleu.corpus_bleu(sys, ref)\n",
    "\n",
    "    prefix = 'BLEU = ' if score_only else ''\n",
    "\n",
    "    print('#### Score Report ####')\n",
    "    print(chrf)\n",
    "    print('{}{}'.format(prefix, bleu.format(score_only=score_only)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "institutional-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_lines = []\n",
    "gold_lines = []\n",
    "all_input_lines = open('../../data/nahuatl-spanish/dev.es').readlines()\n",
    "all_gold_lines = open('../../data/nahuatl-spanish/dev.nah').readlines()\n",
    "\n",
    "for i, (input_sentence, nah_sentence) in enumerate(zip(all_es_lines, all_gold_lines)):\n",
    "    input_sentence = normalizeString(input_sentence)\n",
    "    try:\n",
    "        output_words, _ = evaluate(encoder1, attn_decoder1, input_sentence)\n",
    "        output_sentence = ' '.join(output_words[0:-1])\n",
    "        \n",
    "        system_lines.append(output_sentence)\n",
    "        gold_lines.append(nah_sentence)\n",
    "    except:\n",
    "        pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "induced-affect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System:  in ica teca ihuan ?\n",
      "Gold: ¿ticnequizquia miyac tlamantli tlacualli?\n",
      "\n",
      "System:  tlen ueyi . amo .\n",
      "Gold: ihueltiuh in cihtli ixchipahuac catca\n",
      "\n",
      "System: yehua ce yehua .\n",
      "Gold: Ya quicencuilihqui tlahtoa.\n",
      "\n",
      "System: no komo ya . . .\n",
      "Gold: zan nicpiya $20 itlamiyan queman tlaxtlahuaceh.\n",
      "\n",
      "System: para achiyok para para para .\n",
      "Gold: cualli, amo acah yetoc onpa tlen hueliz nechpalehuizqueh \n",
      "\n",
      "System: san kema ya .\n",
      "Gold: amoqueman quiitac ihueltiuh occepa\n",
      "\n",
      "System: amotlen para ke onca para .\n",
      "Gold: amo acah onpa tlen hueliz nechpalehuizqueh\n",
      "\n",
      "System:  in ! !\n",
      "Gold: ¡Teipanoc!\n",
      "\n",
      "System:  toni quitequipacho ? ?\n",
      "Gold: ¿Tlen ticchiuhticateh ihuan tiquihtoceh?\n",
      "\n",
      "System: amo ce amo ce ce . .\n",
      "Gold: Naman axnicpiya tomintzin.\n",
      "\n",
      "System: yehua amo amo amo .\n",
      "Gold: quena cualli.\n",
      "\n",
      "System: in tlacualli .\n",
      "Gold: nicyecahcicamatic nochi cuac pehuac\n",
      "\n",
      "System: in amo xiquelcahua nopilhuan .\n",
      "Gold: amonicnequi nitlahtoz tlen notahhuan\n",
      "\n",
      "System: san kuali ica in se kitoka .\n",
      "Gold: quichiuhqueh cequin tlamantli achi ceyoc.\n",
      "\n",
      "System:  toni neh mozta ? ?\n",
      "Gold: ¿quenque achtohui tiyah?\n",
      "\n",
      "System:  can in can ? ?\n",
      "Gold: ¿Tlamachtianih zo tatahmeh?\n",
      "\n",
      "System: yehua in in cuicatl .\n",
      "Gold: quicentocaya onpa ihtic\n",
      "\n",
      "System: yehua amo huel .\n",
      "Gold: yehhua amo huelic yahqui\n",
      "\n",
      "System: nochipa eme para cuali . .\n",
      "Gold: totahtzin quiihtoh nequeh yolcameh\n",
      "\n",
      "System: \n",
      "Gold: Nicmachilia tocatzahualli quiyahualoah tlapohualli ihuan quichihuah quentzin xitlanehnehuili.\n",
      "\n",
      "System: ica nehon nehon nehon ika .\n",
      "Gold: hueliceh mitztlaxtlahuiah ica inon.\n",
      "\n",
      "System: seki saj saj yn yn . .\n",
      "Gold: cequin tlacameh axhuelih quinmocuitlahuiah cequinoc tlacameh.\n",
      "\n",
      "System: amo ohuala ya yehua in .\n",
      "Gold: Ahmo nineltoca inon melahuac\n",
      "\n",
      "System: no ya ipan ompa .\n",
      "Gold: Nocicitzin tlacatqui ipan 1899.\n",
      "\n",
      "System: amo nech .\n",
      "Gold: amo niquitah\n",
      "\n",
      "System: tein tata tlen no axcan .\n",
      "Gold: nicchiuhtoc tlen nicpia nicchihuaz axcan\n",
      "\n",
      "System:  in tozan in huel !\n",
      "Gold: ¡ Nochin telpactoyah !\n",
      "\n",
      "System:  ma !\n",
      "Gold: niquitac nochi\n",
      "\n",
      "System: tla komo para tlen .\n",
      "Gold: quena, niman tiquitaz panotoc ica miyac tlamantli.\n",
      "\n",
      "System:  zan uala onca . .\n",
      "Gold: yehhua amo quiihtoh ce tlahtolli\n",
      "\n",
      "System: yn ma oquitac . . .\n",
      "Gold: Nechtlahtlanilihqueh quenque nopeyoh niyahtoya.\n",
      "\n",
      "System: auh yn oncan chanco yn tequanipan .\n",
      "Gold: huan yehhua quiihtoh: Nonantzin, niyetoc nochan\n",
      "\n",
      "System: amo ohuala ipan moztla ipan in .\n",
      "Gold: Axnimopatla queman nitequiti nochan.\n",
      "\n",
      "System: ipan tlen . tlen .\n",
      "Gold: quiitaya ihueltiuh achipa\n",
      "\n",
      "System: mas amo tle mochihua .\n",
      "Gold: nanmechili amonicnequiya nicaquiz zayoh\n",
      "\n",
      "System: nehua zan tlen .\n",
      "Gold: nicnemiliya achipa\n",
      "\n",
      "System: ya ya ni ya uajkino noponi inijuanti noponi\n",
      "Gold: nehhua cualli niyetoya. ¡huan yehhua yahqui nochi!\n",
      "\n",
      "System: tlen tlen ke ika .\n",
      "Gold: nicmati xaihcon niquelnamiqui\n",
      "\n",
      "System: xinechontemoliti cequi ica nitlahtohua .\n",
      "Gold: Hueliz ticmaca tomin ipan huehcatlahtolaztli\n",
      "\n",
      "System: yn ome kenke . .\n",
      "Gold: zatepa niquihtoh quemah. tlamic \n",
      "\n",
      "System: canin ce cualli tonalli .\n",
      "Gold: Yehyectzin tlan ticpiyaz ce canahya canpa tinemiz.\n",
      "\n",
      "System: in tlen tlen ipan ica .\n",
      "Gold: quiilihqueh xicochiti ihuan in tlacatl\n",
      "\n",
      "System: amo nicahci nic .\n",
      "Gold: Axniquilnamiqui quezqui tiquinpiyayah.\n",
      "\n",
      "System: ce cualli kiita ipan itech itech .\n",
      "Gold: Tlahtohtoya ihuan occe ihcuac\n",
      "\n",
      "System: mah lado mah yohui\n",
      "Gold: quiihtohqueh amo hueli niyaz canah\n",
      "\n",
      "System: amo xiquelcahua ipan amo .\n",
      "Gold: Axniquilnamiqui quezqui tequipanoanih tiquinpiyayah.\n",
      "\n",
      "System: seki huan ihuan .\n",
      "Gold: amo tecahcayahuaya huan cualli tlacatl catca\n",
      "\n",
      "System: mas se kimeua iteyotsin .\n",
      "Gold: mochihuac cachi niman\n",
      "\n",
      "System: no yquac de de de . .\n",
      "Gold: Nocicitzin tlacatqui ipan 1 tonalli julio metztli 1910 xihuitl.\n",
      "\n",
      "System: ca incalipan xiquinpiya nopilhuan . .\n",
      "Gold: nocihua ihuan nehuatl ticpiah chicuace\n",
      "\n",
      "System: ce ce ce .\n",
      "Gold: zan huahcahua chicueyi tonalli.\n",
      "\n",
      "System: imojuanti ualase ma\n",
      "Gold: ¿Ticmatih tlen tiquihtoceh?\n",
      "\n",
      "System: amo se\n",
      "Gold: Ticpiyah ce toconetzin.\n",
      "\n",
      "System: amaca kemej\n",
      "Gold: Nimantzin nicahcic.\n",
      "\n",
      "System: pero inijuanti se tonal\n",
      "Gold: zan quichiuhqueh ceyoc tlamantli ica inihhuantin.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sys, gold in zip(system_lines, gold_lines):\n",
    "    print(f'System: {sys}')\n",
    "    print(f'Gold: {gold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "floating-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_report(sys, ref, score_only):\n",
    "\n",
    "    chrf = sacrebleu.corpus_chrf(sys, ref)\n",
    "    bleu = sacrebleu.corpus_bleu(sys, ref)\n",
    "\n",
    "    prefix = 'BLEU = ' if score_only else ''\n",
    "\n",
    "    print('#### Score Report ####')\n",
    "    print(chrf)\n",
    "    print('{}{}'.format(prefix, bleu.format(score_only=score_only)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-contemporary",
   "metadata": {},
   "source": [
    "It is really bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "written-brain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Score Report ####\n",
      "chrF2 = 0.102\n",
      "BLEU = 0.46\n"
     ]
    }
   ],
   "source": [
    "calculate_score_report(system_lines, [gold_lines], score_only=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
